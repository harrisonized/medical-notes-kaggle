{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, auc, roc_auc_score, roc_curve, precision_score, recall_score, accuracy_score, precision_recall_curve, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, normalize\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient() # Creates a client that uses the default port on localhost.\n",
    "database = client.medical_notes_kaggle # Connect to medical_notes_kaggle database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiclass_ROC(y_test, y_score):\n",
    "    \"\"\"\n",
    "    Takes \"y_test\" and \"y_score\" as inputs and returns the fpr, tpr, and roc_auc scores dictionary.\n",
    "    \n",
    "    Taken from scikit-learn's plot_roc tutorial. See below:\n",
    "    https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds, roc_auc = dict(), dict(), dict(), dict()\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC AUC\n",
    "    for i in range(5):\n",
    "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = roc_auc_score(y_test[:,i], y_score[:,i])\n",
    "\n",
    "    # Collect results\n",
    "    fpr[\"micro\"], tpr[\"micro\"], thresholds[\"micro\"] = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(5)])) # Aggregate all false positive rates\n",
    "\n",
    "    # Interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(5):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= 5 # Average it\n",
    "\n",
    "    # Collect Results\n",
    "    fpr[\"macro\"], tpr[\"macro\"] = all_fpr, mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    return fpr, tpr, thresholds, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labeled data\n",
    "mongodb_query = database.train.find({})\n",
    "train_tuple = list(mongodb_query)\n",
    "\n",
    "# Store data in a dataframe\n",
    "train_df = pd.DataFrame(columns=['index_', 'note_text', 'section_headers', 'clinical_domain']) # Create empty dataframe\n",
    "keys_to_exclude = set(('_id', 'index_', 'clinical_domain'))\n",
    "\n",
    "for i in range(len(train_tuple)):\n",
    "    index_int = int(str({v for k,v in train_tuple[i].items() if k in 'index_'})[2:-2])\n",
    "    note_text_str = str({v for k,v in train_tuple[i].items() if k not in keys_to_exclude})[1:-1]\n",
    "    section_headers_str = str({k for k,v in train_tuple[i].items() if k not in keys_to_exclude})[1:-1]\n",
    "    clinical_domain_str = str({v for k,v in train_tuple[i].items() if k in 'clinical_domain'})[2:-2]\n",
    "\n",
    "    train_df = train_df.append(\n",
    "        {'index_': index_int,\n",
    "         'clinical_domain': clinical_domain_str,\n",
    "         'note_text': note_text_str,\n",
    "         'section_headers': section_headers_str}, ignore_index=True)\n",
    "    \n",
    "train_df = train_df.sort_values('index_').reset_index(drop=True) # Sort values to ensure data is in the same order\n",
    "\n",
    "# Drop missing values\n",
    "train_df.section_headers = train_df.section_headers.replace('et(', np.nan)\n",
    "train_df.note_text = train_df.note_text.replace('et(', np.nan)\n",
    "train_df = train_df.dropna().reset_index(drop=True)\n",
    "\n",
    "train_df['text_length'] = train_df.note_text.apply(len) # Add text_length column\n",
    "train_df['section_headers_count'] = train_df.section_headers.apply(lambda x: x.count(',') +1) # Count section headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_</th>\n",
       "      <th>note_text</th>\n",
       "      <th>section_headers</th>\n",
       "      <th>clinical_domain</th>\n",
       "      <th>text_length</th>\n",
       "      <th>section_headers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>'Difficulty with word finding.', 'She did not ...</td>\n",
       "      <td>'CC', 'EXAM', 'FHX', 'HX', 'COURSE', 'SHX', 'M...</td>\n",
       "      <td>Neurology</td>\n",
       "      <td>5433</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>'General.', 'Ganglion of the left wrist.', 'Le...</td>\n",
       "      <td>'PREOPERATIVE DIAGNOSIS', 'OPERATION', 'ESTIMA...</td>\n",
       "      <td>Orthopedic</td>\n",
       "      <td>1432</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>'Less than 100 mL.', 'None.', \"The patient was...</td>\n",
       "      <td>'PREOPERATIVE DIAGNOSIS', 'CONDITION', 'INDICA...</td>\n",
       "      <td>Orthopedic</td>\n",
       "      <td>6452</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>'MRI LEFT SHOULDER', 'There is extensive supra...</td>\n",
       "      <td>'EXAM', 'CLINICAL', 'IMPRESSION', 'FINDINGS'</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>2765</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>'1.  Recurrent bunion deformity, right forefoo...</td>\n",
       "      <td>'ASSESSMENT', 'PLAN/TREATMENT', 'PHYSICAL EXAM...</td>\n",
       "      <td>Orthopedic</td>\n",
       "      <td>3119</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index_                                          note_text  \\\n",
       "0   1001  'Difficulty with word finding.', 'She did not ...   \n",
       "1   1002  'General.', 'Ganglion of the left wrist.', 'Le...   \n",
       "2   1003  'Less than 100 mL.', 'None.', \"The patient was...   \n",
       "3   1004  'MRI LEFT SHOULDER', 'There is extensive supra...   \n",
       "4   1005  '1.  Recurrent bunion deformity, right forefoo...   \n",
       "\n",
       "                                     section_headers clinical_domain  \\\n",
       "0  'CC', 'EXAM', 'FHX', 'HX', 'COURSE', 'SHX', 'M...       Neurology   \n",
       "1  'PREOPERATIVE DIAGNOSIS', 'OPERATION', 'ESTIMA...      Orthopedic   \n",
       "2  'PREOPERATIVE DIAGNOSIS', 'CONDITION', 'INDICA...      Orthopedic   \n",
       "3       'EXAM', 'CLINICAL', 'IMPRESSION', 'FINDINGS'       Radiology   \n",
       "4  'ASSESSMENT', 'PLAN/TREATMENT', 'PHYSICAL EXAM...      Orthopedic   \n",
       "\n",
       "   text_length  section_headers_count  \n",
       "0         5433                      8  \n",
       "1         1432                      5  \n",
       "2         6452                     13  \n",
       "3         2765                      4  \n",
       "4         3119                      8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head() # View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"with\", train_df.note_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
